# -*- coding: utf-8 -*-
"""CEAT - stacked catboost + tablenet (dataset3).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1SAILHQSp_S--h8x5ioAaT-R1w02ccm3E
"""

!pip install pytorch-tabnet catboost scikit-learn openpyxl torch shap

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, ConfusionMatrixDisplay
from pytorch_tabnet.tab_model import TabNetClassifier
from catboost import CatBoostClassifier
from sklearn.ensemble import StackingClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.base import BaseEstimator, ClassifierMixin
import shap
import torch
from torch.optim.lr_scheduler import StepLR
import matplotlib.pyplot as plt

from google.colab import files

# Upload dataset
uploaded = files.upload()
file_name = list(uploaded.keys())[0]

# Read dataset
if file_name.endswith('.xlsx') or file_name.endswith('.xls'):
    df = pd.read_excel(file_name, engine='openpyxl')
elif file_name.endswith('.csv'):
    df = pd.read_csv(file_name)
else:
    raise ValueError("Upload a .xlsx, .xls or .csv file.")

# Drop Country (optional)
df.drop(columns=["Country"], axis=1, inplace=True)

# Feature engineering
df['WorkRestRatio'] = df['Work Hours per Week'] / (df['Sleep Hours'] + 1)

# Target and features
X = df.drop(columns=['Stress Level'])
y = df['Stress Level']

# Identify categorical columns
cat_features = ['Gender', 'Exercise Level', 'Diet Type', 'Mental Health Condition']
for col in cat_features:
    le = LabelEncoder()
    X[col] = le.fit_transform(X[col].astype(str))

# Scaling numerical features
num_cols = [col for col in X.columns if col not in cat_features]
scaler = StandardScaler()
X[num_cols] = scaler.fit_transform(X[num_cols])

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

# Categorical indices and dimensions
cat_idxs = [X.columns.get_loc(col) for col in cat_features]
cat_dims = [len(df[col].unique()) for col in cat_features]

# Wrapper for TabNet
class TabNetWrapper(BaseEstimator, ClassifierMixin):
    def __init__(self, cat_idxs=None, cat_dims=None, cat_emb_dim=8, n_d=8, n_a=8, n_steps=3,
                 gamma=1.3, n_independent=2, n_shared=2, lambda_sparse=0.001, seed=42,
                 optimizer_params={'lr': 2e-2}, scheduler_params={"step_size":50, "gamma":0.9},
                 scheduler_fn=StepLR, mask_type='entmax', verbose=0, max_epochs=200,
                 patience=30, batch_size=64, virtual_batch_size=32):
        self.cat_idxs = cat_idxs
        self.cat_dims = cat_dims
        self.cat_emb_dim = cat_emb_dim
        self.n_d = n_d
        self.n_a = n_a
        self.n_steps = n_steps
        self.gamma = gamma
        self.n_independent = n_independent
        self.n_shared = n_shared
        self.lambda_sparse = lambda_sparse
        self.seed = seed
        self.optimizer_params = optimizer_params
        self.scheduler_params = scheduler_params
        self.scheduler_fn = scheduler_fn
        self.mask_type = mask_type
        self.verbose = verbose
        self.max_epochs = max_epochs
        self.patience = patience
        self.batch_size = batch_size
        self.virtual_batch_size = virtual_batch_size
        self.model = None
        self.classes_ = None

    def fit(self, X, y):
        X_np = X if isinstance(X, np.ndarray) else X.values
        y_np = y if isinstance(y, np.ndarray) else y.values
        self.classes_ = np.unique(y_np)
        self.model = TabNetClassifier(
            cat_idxs=self.cat_idxs,
            cat_dims=self.cat_dims,
            cat_emb_dim=self.cat_emb_dim,
            n_d=self.n_d,
            n_a=self.n_a,
            n_steps=self.n_steps,
            gamma=self.gamma,
            n_independent=self.n_independent,
            n_shared=self.n_shared,
            lambda_sparse=self.lambda_sparse,
            seed=self.seed,
            optimizer_params=self.optimizer_params,
            scheduler_params=self.scheduler_params,
            scheduler_fn=self.scheduler_fn,
            mask_type=self.mask_type,
            verbose=self.verbose,
            device_name='auto',
        )
        self.model.fit(
            X_np, y_np,
            max_epochs=self.max_epochs,
            patience=self.patience,
            batch_size=self.batch_size,
            virtual_batch_size=self.virtual_batch_size,
            num_workers=0,
            drop_last=False,
            eval_set=[(X_np, y_np)],
        )
        return self

    def predict(self, X):
        X_np = X if isinstance(X, np.ndarray) else X.values
        return self.model.predict(X_np)

    def predict_proba(self, X):
        X_np = X if isinstance(X, np.ndarray) else X.values
        return self.model.predict_proba(X_np)

# Initialize models
tabnet_wrapped = TabNetWrapper(cat_idxs=cat_idxs, cat_dims=cat_dims)

catboost_model = CatBoostClassifier(
    iterations=800,
    learning_rate=0.03,
    depth=8,
    l2_leaf_reg=4,
    loss_function='MultiClass',
    random_seed=42,
    verbose=0
)

# Stacking Classifier
stack_model = StackingClassifier(
    estimators=[('tabnet', tabnet_wrapped), ('catboost', catboost_model)],
    final_estimator=LogisticRegression(max_iter=1000),
    cv=5,
    n_jobs=-1,
    passthrough=True
)

# Train the model
stack_model.fit(X_train, y_train)

# Predictions & Evaluation
y_pred = stack_model.predict(X_test)
acc = accuracy_score(y_test, y_pred)
print(f"üî•üî•üî• Highest Accuracy Achieved: {acc:.4f} üî•üî•üî•")

# Confusion matrix
cm = confusion_matrix(y_test, y_pred)
ConfusionMatrixDisplay(confusion_matrix=cm).plot(cmap="Blues")
plt.title("Confusion Matrix üìä")
plt.show()

# Classification report
print("‚úÖ Accuracy:", accuracy_score(y_test, y_pred))
print("\nüìù Classification Report:\n", classification_report(y_test, y_pred))

# SHAP Explainability for CatBoost
catboost_model.fit(X_train, y_train)
explainer = shap.TreeExplainer(catboost_model)
shap_values = explainer.shap_values(X_test)
shap.summary_plot(shap_values, X_test, plot_type='bar')
