# -*- coding: utf-8 -*-
"""CEAT - stacked catboost + tablenet (dataset1).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ArayAYYzeog43bfnZRx03iBW7YfwTVm8
"""

# Install required packages
!pip install pytorch-tabnet catboost scikit-learn openpyxl torch shap --quiet

# Import libraries
import pandas as pd
import numpy as np
import torch
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay, classification_report
from sklearn.ensemble import StackingClassifier
from sklearn.linear_model import LogisticRegression
from catboost import CatBoostClassifier
from pytorch_tabnet.tab_model import TabNetClassifier
from torch.optim.lr_scheduler import StepLR
from sklearn.base import BaseEstimator, ClassifierMixin
import matplotlib.pyplot as plt
from google.colab import files
import shap

# Upload dataset
uploaded = files.upload()
file_name = list(uploaded.keys())[0]

# Read dataset
if file_name.endswith('.xlsx') or file_name.endswith('.xls'):
    df = pd.read_excel(file_name, engine='openpyxl')
elif file_name.endswith('.csv'):
    df = pd.read_csv(file_name)
else:
    raise ValueError("Upload a .xlsx, .xls or .csv file.")

# üëá Custom preprocessing: Drop non-feature columns, select stress label
df = df.drop(columns=['Person ID'], errors='ignore')  # Drop irrelevant ID column
y = df['Stress Level']
X = df.drop(columns=['Stress Level'])

# Identify categorical columns
cat_features = X.select_dtypes(include=['object']).columns.tolist()

# Encode categorical features
for col in cat_features:
    le = LabelEncoder()
    X[col] = le.fit_transform(X[col].astype(str))

# Scale numeric features
num_cols = [col for col in X.columns if col not in cat_features]
scaler = StandardScaler()
X[num_cols] = scaler.fit_transform(X[num_cols])

# Split data
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

# TabNet categorical setup
cat_idxs = [X.columns.get_loc(col) for col in cat_features]
cat_dims = [len(df[col].unique()) for col in cat_features]

# üöÄ Define TabNet Wrapper
class TabNetWrapper(BaseEstimator, ClassifierMixin):
    def __init__(self, cat_idxs=None, cat_dims=None, cat_emb_dim=8, n_d=8, n_a=8, n_steps=3,
                 gamma=1.3, n_independent=2, n_shared=2, lambda_sparse=0.001, seed=42,
                 optimizer_params={'lr': 2e-2}, scheduler_params={"step_size":50, "gamma":0.9},
                 scheduler_fn=StepLR, mask_type='entmax', verbose=0, max_epochs=200,
                 patience=30, batch_size=64, virtual_batch_size=32):
        self.cat_idxs = cat_idxs
        self.cat_dims = cat_dims
        self.cat_emb_dim = cat_emb_dim
        self.n_d = n_d
        self.n_a = n_a
        self.n_steps = n_steps
        self.gamma = gamma
        self.n_independent = n_independent
        self.n_shared = n_shared
        self.lambda_sparse = lambda_sparse
        self.seed = seed
        self.optimizer_params = optimizer_params
        self.scheduler_params = scheduler_params
        self.scheduler_fn = scheduler_fn
        self.mask_type = mask_type
        self.verbose = verbose
        self.max_epochs = max_epochs
        self.patience = patience
        self.batch_size = batch_size
        self.virtual_batch_size = virtual_batch_size
        self.model = None
        self.classes_ = None

    def fit(self, X, y):
        X_np = X.values if hasattr(X, "values") else X
        y_np = y.values if hasattr(y, "values") else y
        self.classes_ = np.unique(y_np)
        self.model = TabNetClassifier(
            cat_idxs=self.cat_idxs,
            cat_dims=self.cat_dims,
            cat_emb_dim=self.cat_emb_dim,
            n_d=self.n_d,
            n_a=self.n_a,
            n_steps=self.n_steps,
            gamma=self.gamma,
            n_independent=self.n_independent,
            n_shared=self.n_shared,
            lambda_sparse=self.lambda_sparse,
            seed=self.seed,
            optimizer_params=self.optimizer_params,
            scheduler_params=self.scheduler_params,
            scheduler_fn=self.scheduler_fn,
            mask_type=self.mask_type,
            verbose=self.verbose,
            device_name='auto'
        )
        self.model.fit(
            X_np, y_np,
            max_epochs=self.max_epochs,
            patience=self.patience,
            batch_size=self.batch_size,
            virtual_batch_size=self.virtual_batch_size,
            num_workers=0,
            drop_last=False,
            eval_set=[(X_np, y_np)]
        )
        return self

    def predict(self, X):
        X_np = X.values if hasattr(X, "values") else X
        return self.model.predict(X_np)

    def predict_proba(self, X):
        X_np = X.values if hasattr(X, "values") else X
        return self.model.predict_proba(X_np)

# Define models
tabnet_wrapped = TabNetWrapper(cat_idxs=cat_idxs, cat_dims=cat_dims)
catboost_model = CatBoostClassifier(
    iterations=800,
    learning_rate=0.03,
    depth=8,
    l2_leaf_reg=4,
    loss_function='MultiClass',
    random_seed=42,
    verbose=0
)
stack_model = StackingClassifier(
    estimators=[('tabnet', tabnet_wrapped), ('catboost', catboost_model)],
    final_estimator=LogisticRegression(max_iter=1000),
    cv=5,
    n_jobs=-1,
    passthrough=True
)

# ‚úÖ Train
stack_model.fit(X_train, y_train)
y_pred = stack_model.predict(X_test)

# ‚úÖ Metrics
acc = accuracy_score(y_test, y_pred)
print(f"\nüî•üî•üî• Highest Accuracy Achieved: {acc:.4f} üî•üî•üî•")

cm = confusion_matrix(y_test, y_pred)
ConfusionMatrixDisplay(confusion_matrix=cm).plot(cmap="Blues")
plt.title("Confusion Matrix üìä")
plt.show()
print("‚úÖ Accuracy:", acc)
print("\nüìù Classification Report:\n", classification_report(y_test, y_pred))

# ‚úÖ SHAP Explainability for CatBoost (fixing NameError)
catboost_model = stack_model.named_estimators_['catboost']
catboost_model.fit(X_train, y_train)
explainer = shap.TreeExplainer(catboost_model)
shap_values = explainer.shap_values(X_test)
shap.summary_plot(shap_values, X_test, plot_type='bar')
